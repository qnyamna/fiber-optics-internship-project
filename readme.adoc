# Fiber Optics DAS Learning Project

🛢️ **Complete Distributed Acoustic Sensing (DAS) Simulator & Analysis Suite**

This project provides a comprehensive learning environment for understanding fiber optic pipeline monitoring technology used by major oil & gas companies worldwide.

![DAS Pipeline Monitoring](complete_das_pipeline_analysis.png)

## 🎯 What You'll Learn

- **Fiber Optic Sensing Technology**: How DAS systems protect pipelines
- **Real-Time Data Streaming**: Kafka, Avro schemas, and industrial IoT
- **Pipeline Monitoring**: Event detection, risk assessment, threat analysis
- **Professional Visualization**: Waterfall plots and monitoring dashboards
- **Data Analysis**: Python tools for processing millions of sensor readings

## 🚀 Quick Start

### 1. Setup (One Time)

> **🆕 Fresh Install Guide**: This section assumes a completely fresh computer. All required software will be installed from scratch.

#### Build Projects (One Time Only)
```bash
# Navigate to schemas directory and build
cd fiberoptics-das-public-schemas-master
./mvnw clean install
cd ..

# Navigate to simulator directory and build  
cd fiberoptics-das-simulator-main
./mvnw clean install
cd ..
```

#### macOS
```bash
# Step 1: Install Docker Desktop
brew install --cask docker
# Alternative: Download from https://www.docker.com/products/docker-desktop/

# Step 2: Install Java 21
brew install openjdk@21

# Step 3: Install Python packages
pip install kafka-python matplotlib numpy pandas seaborn

# Step 4: Setup Java environment
export JAVA_HOME="/usr/local/opt/openjdk@21"  # Intel Mac
export PATH="$JAVA_HOME/bin:$PATH"
```

#### Windows
```cmd
# Step 1: Install Docker Desktop
# Download from: https://www.docker.com/products/docker-desktop/

# Step 2: Install Java 21 - Option 1: Using Chocolatey
choco install openjdk21

# Step 2: Install Java 21 - Option 2: Manual download
# Download from: https://adoptium.net/temurin/releases/?version=21

# Step 3: Install Python
# Download from: https://www.python.org/downloads/

# Step 4: Install Python packages
pip install kafka-python matplotlib numpy pandas seaborn

# Step 5: Setup Java environment (Command Prompt)
set JAVA_HOME=C:\Program Files\Eclipse Adoptium\jdk-21.0.x.x-hotspot
set PATH=%JAVA_HOME%\bin;%PATH%

# Step 5: Setup Java environment (PowerShell)
$env:JAVA_HOME = "C:\Program Files\Eclipse Adoptium\jdk-21.0.x.x-hotspot"
$env:PATH = "$env:JAVA_HOME\bin;$env:PATH"
```

> **Windows Notes**: 
> - Replace `x.x` with your actual version numbers
> - Set environment variables permanently through System Properties > Environment Variables
> - Make sure Docker Desktop is running before proceeding
> - WSL 2 backend is recommended for Docker on Windows

#### Verify Installation (All Platforms)
```bash
# Check Java version (should show version 21.x.x)
java -version

# Check Docker is running (should show version info)
docker --version
docker-compose --version

# Check Python packages (should print success message)
python -c "import kafka, matplotlib, numpy, pandas, seaborn; print('All packages installed successfully')"
```

> **✅ Verification Success**: If all commands above run without errors, your system is ready!

## 📋 Command Reference

### Core Commands (Reference for sections below)

**Start Docker Services:**
```bash
cd "fiberoptics-das-simulator-main"
docker-compose --env-file ./dependson-services/.env -f ./dependson-services/compose-kafka.yml up -d
```

**Stop Docker Services:**
```bash
docker-compose --env-file ./dependson-services/.env -f ./dependson-services/compose-kafka.yml down
```

**Run DAS Simulator:**
- **macOS/Linux:** `source ./das-producer/defaults.env && java -jar ./das-producer/target/das-producer-2.0.12-SNAPSHOT.jar`
- **Windows (CMD):** `for /f "delims=" %%i in (das-producer\defaults.env) do set %%i && java -jar ./das-producer/target/das-producer-2.0.12-SNAPSHOT.jar`
- **Windows (PowerShell):** `Get-Content das-producer\defaults.env | ForEach-Object { if($_ -match '(.*)=(.*)') { [Environment]::SetEnvironmentVariable($matches[1], $matches[2]) } } && java -jar ./das-producer/target/das-producer-2.0.12-SNAPSHOT.jar`

**Analysis Tools:**
- `python3 run_demo_analysis.py` (Always works - creates own data)
- `python3 visual_das_analyzer.py` (Uses real Kafka data if available)
- `python3 view_results.py` (View and explain results)

### 2. Complete Demo Workflow

#### All Platforms
1. **Start services:** Use "Start Docker Services" command above
2. **Wait 30 seconds:** `sleep 30` (macOS/Linux) or `timeout /t 30` (Windows)
3. **Run simulator:** Use "Run DAS Simulator" command for your platform
4. **Create visualizations:** `python3 run_demo_analysis.py` (or `python` on Windows)
5. **View results:** `python3 view_results.py`
6. **Clean up:** Use "Stop Docker Services" command

### 3. Working with Data

Follow the same workflow as "Complete Demo" above. The analysis tools automatically:
- Use real Kafka data if available
- Fall back to demo data if Kafka is empty
- Always produce professional-quality results

> **📝 Note**: Kafka data has temporary retention (hours). If tools show "Using demo data instead", just regenerate fresh data with the simulator.

## 🚀 Daily Operations Guide

### Quick Start (After Initial Setup)
1. Start Docker services (see Command Reference)
2. Wait 30 seconds for initialization
3. Set Java environment if not permanent (see Setup section)
4. Run simulator (see Command Reference)
5. Analyze data with tools
6. Clean up with stop command

### Success Indicators During Run:
- ✅ `Starting DasProducerApplication using Java 21.0.x`
- ✅ `Got TOPIC=..., BOOTSTRAP_SERVERS=broker:9092`
- ✅ `Starting to produce data now for 120 seconds`
- ✅ `We are producing X messages pr second`
- ✅ `Job done. Exiting.` (after 120 seconds)

### One-Liner for Experienced Users:
```bash
cd "fiberoptics-das-simulator-main" && docker-compose --env-file ./dependson-services/.env -f ./dependson-services/compose-kafka.yml up -d && sleep 30 && export JAVA_HOME="/usr/local/opt/openjdk@21" && export PATH="$JAVA_HOME/bin:$PATH" && source ./das-producer/defaults.env && java -jar ./das-producer/target/das-producer-2.0.12-SNAPSHOT.jar
```

## 📊 Generated Visualizations

### Professional Pipeline Monitoring Dashboard
![Complete Analysis](complete_das_pipeline_analysis.png)
- **Waterfall plot**: Time vs distance showing pipeline events
- **Event detection**: Vehicle traffic, digging, leaks, equipment vibration
- **Risk assessment**: Color-coded threat levels (HIGH/MEDIUM/LOW)
- **System dashboard**: Real-time monitoring interface

### Real Simulator Data Analysis
![Data Analysis](comprehensive_das_analysis.png)
- Analysis of actual data from your DAS simulator
- Statistical distributions and frequency analysis
- Data quality metrics and system performance

### Professional Technical Report
```
FIBER OPTICS DAS - PIPELINE MONITORING REPORT
==============================================

EXECUTIVE SUMMARY:
• 4 significant events detected during monitoring period
• Peak disturbance amplitude: 5.276
• System operational status: NORMAL
• Pipeline integrity: MAINTAINED

EVENT #1: Vehicle Traffic Above Pipeline
Risk Level: MEDIUM
Recommended Action: SCHEDULE INSPECTION
```

## 📚 Complete Reference Guide

All documentation has been consolidated into this README for easy access. This single file contains everything you need.

## 🔬 Analysis Tools Reference

| Tool | Purpose | Output | When to Use |
|------|---------|---------|-------------|
| `run_demo_analysis.py` ⭐ | Professional pipeline monitoring demo | `complete_das_pipeline_analysis.png` | **Recommended for beginners** - Always works |
| `visual_das_analyzer.py` | Analyze real simulator data | `comprehensive_das_analysis.png` | After running simulator (uses real Kafka data) |
| `view_results.py` | View and explain all results | Opens visualizations + explanations | To understand what each chart shows |
| `simple_das_consumer.py` | Basic Kafka consumer | `das_data_analysis.png` | Learning Kafka data structure |

### Tool Behavior:
- **`run_demo_analysis.py`**: Creates own realistic data - always works
- **`visual_das_analyzer.py`**: Uses real Kafka data if available, demo data if expired
- **All tools**: Designed to be educational and always produce results

## 🌊 Understanding DAS Technology

### What is Distributed Acoustic Sensing?
DAS uses fiber optic cables as continuous sensors to detect vibrations along pipelines. A laser interrogator sends pulses through the fiber and analyzes backscattered light to detect acoustic events.

### Real-World Applications in Oil & Gas:
- **Pipeline Monitoring**: Leak detection, flow monitoring, pressure changes
- **Security**: Perimeter monitoring, intrusion detection, theft prevention
- **Infrastructure**: Equipment health, predictive maintenance
- **Environmental**: Seismic monitoring, ground movement detection

### The Waterfall Plot (Key Visualization):
```
🌊 WATERFALL PLOT EXPLANATION:
┌─────────────────────────────────────┐
│ Y-Axis: Time progression (seconds)  │
│ X-Axis: Distance along fiber (km)   │
│ Colors: Vibration amplitude levels  │
│                                     │
│ 🔴 Red/Blue: Strong events          │
│ 🟢 Green: Normal background         │
│                                     │
│ Event Patterns:                     │
│ • Vehicle: Diagonal moving lines    │
│ • Digging: Localized bright spots   │
│ • Leaks: Gradual intensity growth   │
│ • Equipment: Regular patterns       │
└─────────────────────────────────────┘
```

## 🏗️ Technical Architecture

### System Components:
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│ DAS Simulator   │───▶│ Kafka Topics    │───▶│ Analysis Tools  │
│ (Java)          │    │ (Avro Schema)   │    │ (Python)        │
└─────────────────┘    └─────────────────┘    └─────────────────┘
        │                        │                        │
        ▼                        ▼                        ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│ • 100 sensors   │    │ • Real-time     │    │ • Waterfall     │
│ • 5000 Hz       │    │   streaming     │    │   plots         │
│ • 120 seconds   │    │ • 130 msg/sec   │    │ • Event         │
│ • ~127M points  │    │ • Avro format   │    │   detection     │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

### Data Flow:
1. **Simulator**: Generates realistic DAS sensor data (replaces physical interrogator)
2. **Kafka**: Streams data in real-time using industry-standard Avro format
3. **Analysis**: Python tools process data and create professional visualizations
4. **Monitoring**: Engineers analyze waterfall plots to detect and assess events

## ⚙️ Advanced Configuration

### Customizing the Simulator

The simulator can be customized by editing `./das-producer/defaults.env`:

```bash
# Duration of data generation
export DURATION_IN_SECONDS=120    # Default: 2 minutes

# Number of sensor points along fiber
export NUMBER_OF_LOCI=100         # Default: 100 sensors

# Maximum sampling frequency  
export MAXIMUM_FREQUENCY=5000.0   # Default: 5 kHz

# Data points per message
export AMPLITUDES_PR_PACKAGE=8192 # Default: 8192 samples
```

### Examples:
```bash
# Run for 5 minutes instead of 2
export DURATION_IN_SECONDS=300

# Simulate longer pipeline (200 sensors)
export NUMBER_OF_LOCI=200

# Higher resolution (10 kHz sampling)
export MAXIMUM_FREQUENCY=10000.0
```

### Data Volume Calculations:
- **Default**: ~127 million data points (100 sensors × 5000 Hz × 120 seconds)
- **5 minutes**: ~318 million data points
- **200 sensors**: ~254 million data points

## 🎓 Learning Outcomes

After completing this project, you understand:

✅ **DAS Technology**: How fiber optic sensors protect critical infrastructure  
✅ **Industrial IoT**: Real-time data streaming with Kafka and Avro  
✅ **Pipeline Operations**: Event detection, risk assessment, monitoring procedures  
✅ **Data Science**: Processing millions of sensor readings with Python  
✅ **Visualization**: Professional monitoring dashboards and waterfall plots  
✅ **Oil & Gas Industry**: Infrastructure protection and operational systems  
✅ **System Integration**: Docker, Java, Kafka, Python ecosystem  
✅ **Real-Time Processing**: Streaming data architecture and analysis  

## 🛠️ System Requirements

- **Java 21**: Required for DAS simulator
- **Docker Desktop**: For Kafka, Schema Registry, PostgreSQL
- **Python 3.8+**: For analysis tools
- **Operating System**: Windows 10/11, macOS, or Linux
- **8GB RAM**: Recommended for smooth operation

## 🚨 Real-World Context

This same technology stack and analysis methods are used by major oil & gas companies to:

- Monitor **thousands of kilometers** of pipelines 24/7
- Detect **leaks within minutes** of occurrence  
- Identify **unauthorized excavation** activities
- Provide **real-time alerts** to operations centers
- **Prevent catastrophic failures** and ensure safety
- **Reduce operational costs** through predictive maintenance

## 🤝 Contributing

This is a learning project for understanding DAS technology. Feel free to:
- Experiment with different event scenarios
- Improve visualization techniques
- Add machine learning anomaly detection
- Explore real data from `FO_DATA_INTERNS_2025/`

## 🛠️ Troubleshooting & FAQ

### Common Setup Issues

#### "Unable to access jarfile"
**Problem**: Wrong directory  
**Fix**: Make sure you're in `fiberoptics-das-simulator-main` directory

#### "source: no such file or directory"
**Problem**: Wrong directory or missing file  
**Fix**: Ensure you're in the simulator directory and file exists
```bash
ls ./das-producer/defaults.env  # Should show the file
```

#### Java version errors
**Problem**: Java environment not set  
**Fix**: Set Java environment (see Setup section for platform-specific commands)

#### Connection refused to Kafka
**Problem**: Docker services not ready  
**Fix**: Wait longer after starting Docker, check with `docker ps`

#### Docker won't start
**Problem**: Docker Desktop not running  
**Fix**: Start Docker Desktop manually and wait for it to fully load

### Analysis Tool Questions

#### "Why do my analysis tools say 'Using demo data instead'?"
**Answer**: Kafka data has temporary retention (hours). This is normal - demo data is equally good for learning! To get fresh real data, just run the simulator again.

#### "Do I need to regenerate data every time?"
**Answer**: No! The analysis tools are smart:
- `run_demo_analysis.py` - Always works (creates own data)
- `visual_das_analyzer.py` - Uses real data if available, demo data if not
- Both produce professional-quality results

#### "What's the difference between real and demo data?"
**Answer**: 
- **Real data**: From your actual simulator run, uses Kafka streaming
- **Demo data**: Mathematically generated with same patterns and events
- **Both**: Show identical pipeline monitoring concepts and visualizations

### Quick Verification Commands
Refer to the "Verify Installation" section under Setup for all verification commands.

## 📞 Support

**Documentation Issues**: Check the guide files in this repository  
**Technical Problems**: Review the troubleshooting sections in setup guides  
**Learning Questions**: Explore the analysis tools and run the demos

---

**🎉 You now understand professional-grade fiber optic pipeline monitoring technology used to protect critical oil & gas infrastructure!**

*Educational project for learning fiber optic pipeline monitoring technology* 